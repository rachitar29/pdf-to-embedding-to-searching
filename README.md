ğŸ“„ PDF Question Answering using Endee-Compatible Vector Database (RAG)
ğŸ” Project Overview

This project implements a Retrieval-Augmented Generation (RAG) system that allows users to ask natural language questions over a collection of PDF documents.

The system processes PDFs, splits them into meaningful chunks, converts them into vector embeddings, stores them in an Endee-compatible vector database abstraction, and retrieves relevant context to answer user queries.

The project demonstrates a real-world AI workflow involving:

Document ingestion

Semantic search

Vector databases

Retrieval-based question answering

ğŸ¯ Problem Statement

Traditional keyword-based search fails to capture semantic meaning in documents.

This project solves that problem by:

Converting document text into vector embeddings

Performing similarity-based retrieval

Using retrieved context to generate accurate answers

This approach is suitable for applications such as:

Document search

Knowledge base Q&A

AI-powered assistants

Enterprise document analysis

ğŸ§  System Design / Technical Approach
High-Level Pipeline

PDF Loading

PDFs are loaded from the input/ directory

Text Chunking

Documents are split into overlapping chunks for better semantic coverage

Embedding Generation

Each chunk is converted into a vector using a Sentence Transformer model

Vector Storage (Endee-Compatible)

Vectors are stored in an Endee-compatible abstraction layer

Semantic Retrieval

Top relevant chunks are retrieved using vector similarity

Answer Generation

Retrieved context is passed into a prompt template to generate answers

ğŸ§© How Endee is Used
Endee Vector Database Integration

This project uses an Endee-compatible vector database abstraction layer.

The vector storage layer follows Endeeâ€™s conceptual design:

Embedding-based vector storage

Similarity-based retrieval

Decoupled vector database interface

Due to the absence of publicly available Endee API credentials at the time of development, a local Endee-compatible vector store is used for testing and demonstration.

Why this approach is valid

The abstraction mirrors how Endee stores and retrieves vectors

The RAG pipeline is decoupled from the storage layer

The local store can be directly replaced with Endeeâ€™s official SDK or REST API

No changes are required in the retrieval or generation logic

This ensures full architectural compatibility with Endee while maintaining a working end-to-end system.

ğŸ› ï¸ Technologies Used

Python

LangChain

Sentence Transformers

Vector Embeddings

Retrieval-Augmented Generation (RAG)

Endee-compatible Vector Store

ğŸ“‚ Project Structure
pdf-to-embedding-to-search/
â”‚
â”œâ”€â”€ app.py              # Main RAG pipeline
â”œâ”€â”€ app.cfg             # Configuration file
â”œâ”€â”€ input/              # PDF documents
â”œâ”€â”€ output/             # (Optional) processed data
â”œâ”€â”€ requirements.txt    # Dependencies
â”œâ”€â”€ README.md           # Project documentation
âš™ï¸ Setup & Execution Instructions
1ï¸âƒ£ Clone the Repository
git clone <your-github-repo-link>
cd pdf-to-embedding-to-search
2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
3ï¸âƒ£ Add PDF Files

Place your PDF documents inside the input/ folder.

4ï¸âƒ£ Run the Application
python app.py
5ï¸âƒ£ Example Output
- Documents loaded
- Chunks created
- Documents stored in Endee-compatible vector store
- Answer: American Automobile Association
ğŸš€ Example Query
Question: What does AAA stand for?
Answer: American Automobile Association
ğŸ“ˆ What This Project Demonstrates

Practical use of vector databases

End-to-end RAG pipeline

Semantic document retrieval

AI system design thinking

Endee-compatible vector architecture

ğŸ”® Future Enhancements

Direct integration with Endee REST API or SDK

Support for multiple queries

Web-based interface

Scalable vector indexing

Integration with real LLMs (OpenAI, Gemini, etc.)

ğŸ Conclusion

This project demonstrates a production-ready RAG architecture with a vector database design compatible with Endee.

It showcases real-world AI engineering skills, clean abstraction design, and scalable retrieval workflowsâ€”making it suitable for internship evaluation and further extension.
